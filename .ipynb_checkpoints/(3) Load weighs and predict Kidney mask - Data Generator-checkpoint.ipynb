{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c34b8662",
   "metadata": {},
   "source": [
    "# Use this code to predict kindey boundaries based on the trained models from section (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c8ae59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "keras-unet init: TF version is >= 2.0.0 - using `tf.keras` instead of `Keras`\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import measure\n",
    "from skimage.transform import resize\n",
    "from keras_unet.metrics import dice_coef\n",
    "from keras_unet.models import custom_unet\n",
    "from keras_unet.losses import jaccard_distance\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "import fnmatch\n",
    "import nibabel as nib\n",
    "import shutil\n",
    "from skimage.segmentation import mark_boundaries, find_boundaries\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7fc321d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_images(data_path):\n",
    "    images = []\n",
    "    path = data_path + '\\\\'\n",
    "    for f in os.listdir(data_path):\n",
    "      if '_K' in f:\n",
    "        continue\n",
    "      elif '_C' in f:\n",
    "        continue\n",
    "      else:\n",
    "        images.append(f)\n",
    "        #segmentations.append(f.replace('.nii', '_K.nii'))\n",
    "\n",
    "    #print(images[0], segmentations[0])\n",
    "    images = np.array(images)\n",
    "    #segmentations = np.array(segmentations)\n",
    "\n",
    "    indices = np.array(range(len(images))) # we will use this in the next step.\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3c425b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gather_set(data_path, phrase):\n",
    "    set_of = []\n",
    "    path = data_path + '\\\\'\n",
    "    for f in os.listdir(data_path):\n",
    "      if phrase in f:\n",
    "        set_of.append(f)\n",
    "      else:\n",
    "        continue\n",
    "    #set_of = np.array(set_of)\n",
    "\n",
    "    indices = np.array(range(len(set_of))) # we will use this in the next step.\n",
    "\n",
    "    return set_of"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb2064d",
   "metadata": {},
   "source": [
    "# Load in the model that was saved\n",
    "\n",
    "\n",
    "# make sure to match the sizes and class numbers\n",
    "\n",
    "\n",
    "This code assumes that the model is saved in the same location that this jupyter notebook is saved, if not make sure to put the full filepath in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed66d513",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = custom_unet(input_shape=(512,512,1), num_classes=2)\n",
    "#UNET_KU_EM_UB_train_MA_val\n",
    "#UNET_MA_EM_UB_train_KU_val\n",
    "#UNET_MA_KU_EM_train_UB_val\n",
    "#UNET_MA_KU_UB_train_EM_val\n",
    "#ALL_INSTITUTION_80-20\n",
    "model.load_weights('UAB-kidneys-35.h5')\n",
    "model_name = 'UAB-kidneys-35'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7c51ed",
   "metadata": {},
   "source": [
    "Define the path of the images that will be predicted on\n",
    "\n",
    "this assumes there is one folder where all of the images are located with the masks defined by prefixes and subfixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ba7ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#data_path = r'C:\\Users\\UAB\\data\\Emory\\data'\n",
    "#data_path = r'C:\\Users\\UAB\\data\\Mayo\\data'\n",
    "#data_path = r'C:\\Users\\UAB\\data\\UAB\\data'\n",
    "data_path = r'C:\\Users\\UAB\\data\\KU\\data'\n",
    "images = gather_images(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97057c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KU_101934_0_96_L_0_M.npy\n",
      "26082\n",
      "['KU_101934_0_96_L_0_M.npy' 'KU_101934_0_96_L_10_M.npy']\n"
     ]
    }
   ],
   "source": [
    "print(images[0])\n",
    "print(len(images))\n",
    "print(images[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fc6b34",
   "metadata": {},
   "source": [
    "# Specify if specific testing list - this will gather images left out for testing, you can also use random images if you want\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11bc5687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11399 L\n",
      "13948 R\n",
      "15792 R\n",
      "18341 R\n",
      "18671 L\n",
      "18671 R\n",
      "18745 L\n"
     ]
    }
   ],
   "source": [
    "image_list = []\n",
    "#Emory\n",
    "#phrase_list = ['283935R','290336L','290336R','295106L','295106R']\n",
    "#Mayo\n",
    "#phrase_list = ['380166R','383193L','383193R','385151L','385151R']\n",
    "#UAB\n",
    "#phrase_list = ['457036L','457036R']\n",
    "#KU\n",
    "phrase_list = ['113994L','139486R','157925R','183417R','186714L','186714R','187456L']\n",
    "\n",
    "for i in range(len(phrase_list)):\n",
    "    phrase1 = phrase_list[i][:-2]\n",
    "    phrase2 = phrase_list[i][-1]\n",
    "    print(phrase1, phrase2)\n",
    "    for z in range(len(images)):\n",
    "        name = images[z]\n",
    "        if phrase1 in name:\n",
    "            if phrase2 in name:\n",
    "                image_list.append(name)\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4391d910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26082\n",
      "3117\n"
     ]
    }
   ],
   "source": [
    "print(len(images))\n",
    "images = image_list\n",
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6fb55a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "for i in images:\n",
    "    if i not in d:\n",
    "        d[i] = len(d)\n",
    "\n",
    "labels_mapping = list(map(d.get, images))\n",
    "#print(labels_mapping)\n",
    "\n",
    "labels = {images[i]:labels_mapping[i] for i in range(len(images))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3cac3990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3117\n"
     ]
    }
   ],
   "source": [
    "print(len(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0387b3",
   "metadata": {},
   "source": [
    "## We need to gather a stack of 32 images for the prediction in the shape (32, 512, 512, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fae68d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide the number of images avaliable into batches of 32, then we can feed it a batch at a time and \n",
    "# then we can append to the larger stack\n",
    "\n",
    "\n",
    "\n",
    "label_list = []\n",
    "predictions = []\n",
    "pred_path = r\"C:\\Users\\UAB\\data\\KU\\data\" #MAKE SURE TO DEFINE A SAVE FILE PATH\n",
    "images = images\n",
    "\n",
    "batches = len(images)//32\n",
    "left_over = len(images)%32 \n",
    "print(batches, left_over)\n",
    "\n",
    "\n",
    "#REMEMBER TO COME BACK FOR LEFTOVERS\n",
    "for i in range(batches):\n",
    "    image_stack = np.empty((32,512,512,1))\n",
    "    for x in range(32*i, (32*(i+1))):\n",
    "        image = np.load(data_path +\"\\\\\"+images[x])\n",
    "        y = x-(32*i)\n",
    "        #print(x, y)\n",
    "        image_stack[y, ...,0] = image[...]\n",
    "        label_match = str(images[x][:-5] + 'K.npy')\n",
    "        #print(label_match)\n",
    "        label_list.append(label_match)\n",
    "        \n",
    "    img_prediction = model.predict(image_stack)\n",
    "    img_prediction = img_prediction.astype('uint8')\n",
    "    #print(img_prediction.shape)\n",
    "    #print(img_prediction.shape)\n",
    "    for z in range(len(img_prediction)):\n",
    "        #print('saving images')\n",
    "        img_numb = z + 32*i\n",
    "        #print(z, img_numb)\n",
    "        image_save = img_prediction[z,:,:]\n",
    "        #image_save = find_boundaries(image_save, mode='thick').astype(np.uint8)\n",
    "        label = label_list[img_numb][:-5]\n",
    "        filename = str(label + model_name + '_K.npy')\n",
    "        save_file = np.uint8(image_save[:,:,1])\n",
    "        np.save(os.path.join(pred_path, filename),save_file)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6248b89a",
   "metadata": {},
   "source": [
    "Get left over images predicted on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ba09c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "KU_187456_3_120_L_89_M.npy\n"
     ]
    }
   ],
   "source": [
    "left_images = images[-left_over:]\n",
    "print(len(left_images))\n",
    "print(left_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "60fa0b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_stack = np.empty((32,512,512,1))\n",
    "label_left = []\n",
    "for i in range(len(left_images)):\n",
    "    image = np.load(data_path +\"\\\\\"+left_images[i])\n",
    "    image_stack[i, ...,0] = image[...]\n",
    "    label_match = str(left_images[i][:-5] + 'K.npy')\n",
    "    label_left.append(label_match)\n",
    "img_prediction = model.predict(image_stack)\n",
    "img_prediction = img_prediction.astype('float')\n",
    "\n",
    "for z in range(len(left_images)):\n",
    "        #print('saving images')\n",
    "        #print(z, img_numb)\n",
    "        image_save = img_prediction[z,:,:]\n",
    "        label = label_left[z][:-5]\n",
    "        filename = str(label + model_name + '_K.npy')\n",
    "        save_file = np.uint8(image_save[:,:,1])\n",
    "        np.save(os.path.join(pred_path, filename), save_file)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51496fc4",
   "metadata": {},
   "source": [
    "# Look at predicted images - optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8beec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r'C:\\Users\\UAB\\data\\UAB\\AllNPY'\n",
    "images = gather_images(data_path)\n",
    "\n",
    "d = {}\n",
    "for i in images:\n",
    "    if i not in d:\n",
    "        d[i] = len(d)\n",
    "\n",
    "labels_mapping = list(map(d.get, images))\n",
    "#print(labels_mapping)\n",
    "\n",
    "labels = {images[i]:labels_mapping[i] for i in range(len(images))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6877f416",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('UAB-kidneys-35.h5')\n",
    "model_name = 'UAB-kidneys-35'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d402127a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_names = images[0:31]\n",
    "image_stack = np.empty((32,512,512,1))\n",
    "label_list = []\n",
    "for i in range(len(image_names)):\n",
    "    image = np.load(data_path +\"\\\\\"+images[i])\n",
    "    image_stack[i, ...,0] = image[...]\n",
    "    label_match = str(images[i][:-5] + 'K.npy')\n",
    "    label_list.append(label_match)\n",
    "\n",
    "print(image_stack.shape)\n",
    "print(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3250d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_prediction = model.predict(image_stack)\n",
    "img_prediction = img_prediction.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72542b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "img_prediction_30 = img_prediction[n,:,:,1]\n",
    "plt.figure()\n",
    "f, axarr = plt.subplots(nrows = 1, ncols = 3, figsize=(10,10))\n",
    "f.tight_layout()\n",
    "\n",
    "axarr[0].imshow(image_stack[n,:,:,0], cmap=\"gray\")\n",
    "axarr[0].title.set_text('Original Image')\n",
    "axarr[1].imshow(og_seg, cmap='gray')\n",
    "axarr[1].title.set_text('Truth Segmentation')\n",
    "axarr[2].imshow(segmentation, cmap='gray')\n",
    "axarr[2].title.set_text('Predicted Segmentation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf0c513",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predicition(image_stack, n):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(image_stack[n,:,:,0], cmap=plt.cm.gray)\n",
    "    og_seg = np.load(data_path +\"\\\\\"+label_list[n])\n",
    "    segmentation = img_prediction[n,:,:,]\n",
    "    segmentation = segmentation[:,:,1]\n",
    "\n",
    "    contours = measure.find_contours(og_seg, 0.8)\n",
    "    for j,contour in enumerate(contours):\n",
    "        ax.plot(contour[:, 1], contour[:, 0],color='#FB3640', lw=2)\n",
    "        contours = measure.find_contours(segmentation, 0.8)\n",
    "        for contour in contours:\n",
    "            ax.plot(contour[:, 1], contour[:, 0],color='#35A7FF', lw=2)\n",
    "\n",
    "    ax.axis('image')\n",
    "    ax.title.set_text('red is orignal - blue is prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f04d6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_predicition(image_stack, 15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF23",
   "language": "python",
   "name": "tf23"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
